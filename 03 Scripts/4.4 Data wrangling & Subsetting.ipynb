{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88fcc3bf",
   "metadata": {},
   "source": [
    "## Imort libraries and dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43b4bc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/constantinmelachrinos/Documents/careerfoundry data analyst/Course files/Data Analytics Immersion/Achievement 4 - InstaCart - Python/Instacart Basket Analysis/02 Data/Original Data/orders.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/constantinmelachrinos/Documents/careerfoundry data analyst/Course files/Data Analytics Immersion/Achievement 4 - InstaCart - Python/Instacart Basket Analysis\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#import Instacart data_sets\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df_ords \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02 Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morders.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     11\u001b[0m df_prods \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02 Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducts.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     12\u001b[0m df_dep \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m02 Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOriginal Data\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepartments.csv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/constantinmelachrinos/Documents/careerfoundry data analyst/Course files/Data Analytics Immersion/Achievement 4 - InstaCart - Python/Instacart Basket Analysis/02 Data/Original Data/orders.csv'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#set scripts path in variable 'path'\n",
    "path = r'/Users/constantinmelachrinos/Documents/careerfoundry data analyst/Course files/Data Analytics Immersion/Achievement 4 - InstaCart - Python/Instacart Basket Analysis'\n",
    "\n",
    "#import Instacart data_sets\n",
    "df_ords = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'orders.csv'))\n",
    "df_prods = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'products.csv'))\n",
    "df_dep = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'departments.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec33daa5",
   "metadata": {},
   "source": [
    "## Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3dc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column 'eval_set' from orders dataframe\n",
    "df_ords = df_ords.drop(columns = ['eval_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fec8dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if column actually dropped\n",
    "df_ords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6989484a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify missing values in column 'days_since_prior_order'\n",
    "df_ords['days_since_prior_order'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c7dab2",
   "metadata": {},
   "source": [
    "## Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename 'order_dow' column to 'order_day_of_week'\n",
    "df_ords.rename(columns = {'order_dow' : 'orders_day_of_week'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fba399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if column name is actually changed\n",
    "df_ords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aea788d",
   "metadata": {},
   "source": [
    "## changing data type of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0589637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type 'order_id' to string \n",
    "df_ords['order_id'] = df_ords['order_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39686b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if data type actually changed\n",
    "df_ords['order_id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d4421",
   "metadata": {},
   "source": [
    "# Transposing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002a81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check dataframe 'department' on it's look. currently its in 'wide format'. \n",
    "df_dep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose dataframe to 'long format'\n",
    "df_dep.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562cfb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save transposed dataframe in new name 'df_dep_T'\n",
    "df_dep_T=df_dep.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaca1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if executed accordingly\n",
    "df_dep_T.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac481eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the index of the dataframe\n",
    "df_dep_T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82629b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write row 0 from df_dep_T in new header in variable with the iloc function\n",
    "new_header = df_dep_T.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c15ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if new_header is correct\n",
    "new_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22b8f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy everything from dataframe df_dep_T to df_dep_T_new except the first row\n",
    "df_dep_T_new = df_dep_T[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace233ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if new dataframe is correctly copied\n",
    "df_dep_T_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c539252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy list of new header in new_header in the new data frame header of df_dep_T_new\n",
    "df_dep_T_new.columns = new_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188aac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if new header is shown correctly\n",
    "df_dep_T_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee95c1",
   "metadata": {},
   "source": [
    "## Data dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data dictionary of df_dep_T_new\n",
    "data_dict = df_dep_T_new.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if executed correctly\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba80e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check department of data dictionary '19'. Its snacks.\n",
    "print(data_dict.get('19'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f828e67",
   "metadata": {},
   "source": [
    "## Subsetting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33851ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subesetting in df_prods where department_id is '19'\n",
    "df_snacks =  df_prods[df_prods['department_id']==19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ef341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if executed correctly and only show data where department_id is '19'\n",
    "df_snacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58727dd0",
   "metadata": {},
   "source": [
    "## Task step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5105e55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a variable which that doesn’t need to be included in your analysis as a numeric variable \n",
    "# and change it to a suitable format in dataframe 'orders'.\n",
    "df_ords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the chosen variabel is 'order_id' since its not necessary for our analysis as a numeric value.\n",
    "df_ords['order_id'] = df_ords['order_id'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7903af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if it actually changed\n",
    "df_ords['order_id'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fa23fd",
   "metadata": {},
   "source": [
    "## Task step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5850e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for a variable in your df_ords dataframe with an unintuitive name \n",
    "# and change its name without overwriting the dataframe.\n",
    "# orders_dow is such a variable. Should be changed to 'orders_day_of_week'\n",
    "df_ords.rename(columns = {'order_dow' : 'orders_day_of_week'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if executed correctly\n",
    "df_ords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae4857",
   "metadata": {},
   "source": [
    "## Task step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e73886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your client wants to know what the busiest hour is for placing orders. \n",
    "#Find the frequency of the corresponding variable and share your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb659b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how many times the hour occured in the dataframe\n",
    "df_ords['order_hour_of_day'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab70c216",
   "metadata": {},
   "source": [
    "### 10 oclock is the busiest hour in the day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f081183",
   "metadata": {},
   "source": [
    "## Task step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037fc44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the meaning behind a value of 4 in the \"department_id\" column \n",
    "# within the df_prods dataframe using a data dictionary.\n",
    "print(data_dict.get('4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbb182a",
   "metadata": {},
   "source": [
    "### the meaning of the value 4 is the 'produce' department"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322186df",
   "metadata": {},
   "source": [
    "## Task step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86018e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sales team in your client’s organization wants to know more about breakfast item sales. \n",
    "#Create a subset containing only the required information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685ef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify department_id of breakfast item.\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a11c01b",
   "metadata": {},
   "source": [
    "### the breakfast department has the id of '14'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d13232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subesetting in df_prods where department_id is '14'\n",
    "df_breakfast =  df_prods[df_prods['department_id']==14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb75cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if executed correctly\n",
    "df_breakfast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7762e5",
   "metadata": {},
   "source": [
    "## Task step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#They’d also like to see details about products that customers might use to throw dinner parties. \n",
    "#Your task is to find all observations from the entire dataframe that include items from the following departments:\n",
    "#alcohol, deli, beverages, and meat/seafood. You’ll need to present this subset to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check department ID's for the sections needed.\n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c080c2ad",
   "metadata": {},
   "source": [
    "### acohol = 5, deli = 20, beverages = 7, meat/seafood = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fb4f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe products on all the involved departments with the isin function\n",
    "df_dinner_parties = df_prods.loc[df_prods['department_id'].isin([5,20,7,12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ac14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if executed correctly\n",
    "df_dinner_parties.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f34a128",
   "metadata": {},
   "source": [
    "## Task step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c5914",
   "metadata": {},
   "outputs": [],
   "source": [
    "#It’s important that you keep track of total counts in your dataframes. \n",
    "#How many rows does the last dataframe you created have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf00df32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chek how many rows and columns the dataframe has\n",
    "df_dinner_parties.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62511d6",
   "metadata": {},
   "source": [
    "### it has 7650 rows and 5 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3aaa7",
   "metadata": {},
   "source": [
    "## Task step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d377bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Someone from the data engineers team in Instacart thinks they’ve spotted something strange \n",
    "#about the customer with a \"user_id\" of “1.” Extract all the information you can about this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e7088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter orders dataframe on user_id '1' and write in new dataframe called 'df_uder_id_1'\n",
    "df_user_id_1=df_ords[df_ords['user_id']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc4c801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show dataframe to check if its correct\n",
    "df_user_id_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7a9084",
   "metadata": {},
   "source": [
    "## Task step 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625c14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You also need to provide some details about this user’s behavior. \n",
    "#What basic stats can you provide based on the information you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b71ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check stats on user with user_id '1'\n",
    "df_user_id_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9785f6",
   "metadata": {},
   "source": [
    "### User ordered 11 times. he orders between 7 AM and 16 PM. Maximum time between orders is 30 days. \n",
    "### He orders only from monday to thursday. Never from friday till sunday."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99ae3c",
   "metadata": {},
   "source": [
    "## Task step 12 and 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e962c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export your df_ords dataframe as “orders_wrangled.csv” in your “Prepared Data” folder.\n",
    "df_ords.to_csv(os.path.join(path, '02 Data','Prepared Data', 'orders_wrangled.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cc4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export the df_dep_t_new dataframe as “departments_wrangled.csv” in your “Prepared Data” folder \n",
    "#so that you have a “.csv” file of your departments data in the correct format.\n",
    "df_dep_T_new.to_csv(os.path.join(path, '02 Data','Prepared Data', 'departments_wrangled.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae4b50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
